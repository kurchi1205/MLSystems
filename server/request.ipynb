{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:\n",
    "1. Run `python api.py --init-quota 200 --max-generated-tokens 50` to start the server.\n",
    "2. Run this script to test the server.\n",
    "\n",
    "You MUST keep the logs of this file in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "import aiohttp\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AsyncLLMServiceTester:\n",
    "    def __init__(self, base_url: str = \"http://localhost:8000\"):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.session = None\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "\n",
    "    async def generate(self, prompt: str) -> Dict:\n",
    "        \"\"\"generate response\"\"\"\n",
    "        # TODO: generate function call\n",
    "        # you need to post a request to the server\n",
    "        # and parse the response in async way\n",
    "        # the response is a json with the following format:\n",
    "        # {\n",
    "        #     \"status\": \"success\" or \"error\",\n",
    "        #     \"text\": \"the generated text\"\n",
    "        # }\n",
    "        # ==== start your code here ====\n",
    "        data = {\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "        async with self.session.post(self.base_url + \"/generate\", json=data) as response:\n",
    "            status = response.status\n",
    "            text = await response.text()\n",
    "            result = {\n",
    "                \"status\": status,\n",
    "                \"text\": text\n",
    "            }\n",
    "        return result\n",
    "        # ==== end of your code ====\n",
    "\n",
    "    async def process_test_case(self, test_case: Dict) -> Dict:\n",
    "        \"\"\"Process a single test case\"\"\"\n",
    "\n",
    "        await asyncio.sleep(random.uniform(0, 2))  # random delay\n",
    "        print(f\"Submitting test case: {test_case['prompt']}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        result = await self.generate(test_case[\"prompt\"])\n",
    "        end_time = time.time()\n",
    "\n",
    "        return {\n",
    "            \"test_case\": test_case,\n",
    "            \"result\": result,\n",
    "            \"time_taken\": end_time - start_time,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with 5 test cases...\n",
      "Submitting test case: Write a poem about spring.\n",
      "Submitting test case: What is the capital of France? And what is the capital of Canada?\n",
      "Submitting test case: Explain quantum computing in 50 words.\n",
      "Submitting test case: Write a recipe for chocolate cake.\n",
      "Submitting test case: Hello, how are you?\n",
      "\n",
      "=== Test Case 1 ===\n",
      "Prompt: Hello, how are you?\n",
      "Time taken: 0.08 seconds\n",
      "Status: 200\n",
      "Response: {\"text\":\" I\",\"status\":\"pending\"}\n",
      "==================================================\n",
      "\n",
      "=== Test Case 2 ===\n",
      "Prompt: What is the capital of France? And what is the capital of Canada?\n",
      "Time taken: 0.08 seconds\n",
      "Status: 200\n",
      "Response: {\"text\":\" Paris\",\"status\":\"pending\"}\n",
      "==================================================\n",
      "\n",
      "=== Test Case 3 ===\n",
      "Prompt: Write a poem about spring.\n",
      "Time taken: 0.77 seconds\n",
      "Status: 200\n",
      "Response: {\"text\":\" The\",\"status\":\"pending\"}\n",
      "==================================================\n",
      "\n",
      "=== Test Case 4 ===\n",
      "Prompt: Explain quantum computing in 50 words.\n",
      "Time taken: 0.10 seconds\n",
      "Status: 200\n",
      "Response: {\"text\":\" Quantum\",\"status\":\"pending\"}\n",
      "==================================================\n",
      "\n",
      "=== Test Case 5 ===\n",
      "Prompt: Write a recipe for chocolate cake.\n",
      "Time taken: 0.07 seconds\n",
      "Status: 200\n",
      "Response: {\"text\":\" Moist\",\"status\":\"pending\"}\n",
      "==================================================\n",
      "\n",
      "Test Summary:\n",
      "Total time: 1.88 seconds\n",
      "Average time per request: 0.38 seconds\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async def main():\n",
    "    test_cases = [\n",
    "        {\"prompt\": \"Hello, how are you?\"},\n",
    "        {\"prompt\": \"What is the capital of France? And what is the capital of Canada?\"},\n",
    "        {\"prompt\": \"Write a poem about spring.\"},\n",
    "        {\"prompt\": \"Explain quantum computing in 50 words.\"},\n",
    "        {\"prompt\": \"Write a recipe for chocolate cake.\"},\n",
    "    ]\n",
    "\n",
    "    print(f\"Starting test with {len(test_cases)} test cases...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with AsyncLLMServiceTester() as tester:\n",
    "        # create submit coroutines\n",
    "        submit_coroutines = [\n",
    "            tester.process_test_case(test_case) for test_case in test_cases\n",
    "        ]\n",
    "\n",
    "        # run all submit coroutines\n",
    "        results = await asyncio.gather(*submit_coroutines)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # print results\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n=== Test Case {i} ===\")\n",
    "        print(f\"Prompt: {result['test_case']['prompt']}\")\n",
    "        print(f\"Time taken: {result['time_taken']:.2f} seconds\")\n",
    "        print(f\"Status: {result['result']['status']}\")\n",
    "        print(f\"Response: {result['result']['text']}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "    print(f\"\\nTest Summary:\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per request: {total_time/len(test_cases):.2f} seconds\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
